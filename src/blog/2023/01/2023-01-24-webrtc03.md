---
slug: "/webrtc03/"
layout: post
date: 2023-01-24 13:49:15 +0900
title: "[WEBRTC] 3인 이상 영상 교환하는 원리를 알아보자"
author: Kimson
categories: [javascript]
image: /images/post/covers/TIL-javascript.png
tags: [javascript, webrtc, icecandidate, multi-stream]
description: "WebRTC를 단계별로 알아보자

WebRTC를 처음 접한 때는 작년 5~6월 즈음인 것 같습니다. 당시 미디어 관련한 작업 때문에 ffmpeg와 같이 리딩하고 있었는데요. 그 뒤로 이직을 하면서 공백기간 동안 포트폴리오를 정리하느라 손대지 못하고 있다가 이직한 회사에서 때마침 필요로 하는 기회가 생겨 다시 시작하게 되었습니다.

이전 1, 2편으로 WebRTC에 대해 포스팅 한 적이 있습니다. 지금 읽어보니 틀린부분도 있고 해서 포스팅을 수정하기보다 새로 올려서 조금 다른 주제로 포스팅을 하려 합니다."
featured: true
hidden: false
rating: 4.5
toc: true
profile: false
istop: true
keysum: false
keywords: ""
published: true
---

# WebRTC를 단계별로 알아보자

WebRTC를 처음 접한 때는 작년 5~6월 즈음인 것 같습니다. 당시 미디어 관련한 작업 때문에 ffmpeg와 같이 리딩하고 있었는데요. 그 뒤로 이직을 하면서 공백기간 동안 포트폴리오를 정리하느라 손대지 못하고 있다가 이직한 회사에서 때마침 필요로 하는 기회가 생겨 다시 시작하게 되었습니다.

이전 1, 2편으로 WebRTC에 대해 포스팅 한 적이 있습니다. 지금 읽어보니 틀린부분도 있고 해서 포스팅을 수정하기보다 새로 올려서 조금 다른 주제로 포스팅을 하려 합니다.

## 개인의 미디어 스트림을 띄우기는 쉽다

자신의 화상카메라로 본인을 웹 상에 비디오로 올리는 것은 매우 간단합니다. 별로 머리를 쓸 것도 없이 navigator api를 사용하면 카메라 권한 요청을 하고 손 쉽게 영상을 띄울 수 있습니다. 사용법은 아래와 같습니다.

```javascript
navigator.mediaDevices.getUserMedia({
 video: true,
 audio: false,
}).then((stream) => {
 const video = document.createElement('video');
 video.autoplay = true;
 // video.srcObject = stream;
 video.srcObject = stream;
});
```

위 코드가 동작하면 브라우저 상단 주소줄 부근에 카메라 또는 마이크 권한 요청 팝업이 뜹니다. 사용하는 브라우저 앱마다 뜨는 위치는 조금 다른 걸로 압니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214215604-c48fc18c-4f04-4758-af74-38222dfc2df7.png" alt="sample" title="sample">
   <figcaption>예시 이미지</figcaption>
</span>
</figure>

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214216245-44e97204-056c-438e-8d7d-abd84df91be5.png" alt="sample" title="sample">
   <figcaption>예시 이미지</figcaption>
</span>
</figure>

단일로 영상을 띄우는 것은 쉽지만 1대1 혹은 1대N 영상교환하는 작업을 하게 되면 시그널링 서버가 필요하게 됩니다.

필자의 경우는 소켓서버를 사용할 예정이고 소켓서버에 사용되는 라이브러리는 `uWebSockets.js`를 사용하고 있습니다.

## 시그널링 서버 작성

1대1만 고려해서 작업하다보면 어려움을 겪을 수 있습니다. 1대N을 염두에 두고 작업하는 것이 좋은데요, 이유는 1대1로 영상교환하는 원리가 3인 이상일 때 조금 다르게 적용이 되어야 하기 때문입니다.

기본 동작원리는 다를 것은 없습니다만 고려해야하는 부분이 생깁니다.

먼저 원리를 보면 아래와 같습니다.

1. 사용자 A가 입장한다.
2. A는 localStream과 localVideo를 가지고 있고, 앞서 말한 getUserMedia로 영상을 띄운다.
3. A는 offer를 생성하고 localDescription에 생성한 offer를 저장한다.
4. B가 입장한다. 1, 2, 3번과 같은 과정을 거치고 offer를 A에게 보낸다.
5. A는 B의 offer를 받고 remoteDescription에 받은 offer를 저장한다.
6. 그리고 A는 answer를 생성하여 A의 localDescription에 저장하고 B에게 answer를 보낸다.
7. B는 answer를 받고 B의 remoteDescription에 받은 answer를 저장한다.

큰 골자로 보면 위의 과정이 이루어집니다. 물론 교환하는 과정에서 icecandidate이벤트가 발생하면서 후보군 교환이 이루어집니다. 그리고 track이벤트도 발생하면서 원격 영상의 track정보를 받아오게 됩니다.

코드로 보면 다음과 같습니다.

```javascript
// server.js

/* A quite detailed WebSockets example */

const uWs = require('uWebSockets.js');
const port = 3000;

const app = uWs./*SSL*/App().ws('/*', {
  /* Options */
  compression: uWs.SHARED_COMPRESSOR,
  maxPayloadLength: 16 * 1024 * 1024,
  idleTimeout: 10,
  /* Handlers */
  open: (ws) => {
    console.log('A WebSocket connected with URL: ' + ws.myData);
   ws.subscribe('broadcast');
  },
  message: (ws, message, isBinary) => {
    /* Ok is false if backpressure was built up, wait for drain */
    let ok = ws.publish('broadcast', message, isBinary);
  },
  drain: (ws) => {
    console.log('WebSocket backpressure: ' + ws.getBufferedAmount());
  },
  close: (ws, code, message) => {
    console.log('WebSocket closed');
  }
}).listen(port, (token) => {
  if (token) {
    console.log('Listening to port ' + port);
  } else {
    console.log('Failed to listen to port ' + port);
  }
});
```

별 기능없이 주고 받는 기능만 있으면 됩니다. 단, 본인을 제외한 모든 사용자에게 데이터를 주어야 하므로 `broadcast`를 하겠습니다. 이걸로 간단하게 시그널링 서버는 끝이 납니다.

## 프론트 부분을 작성하자

다음으로 프론트 부분입니다. 이제 조금씩 복잡해질텐데요. 하나씩 뜯어보면 원리를 이해하기 쉽습니다.

제가 시도한 방법은 2편에 나온 이미지를 단계별로 조작할 수 있도록 직접 만들고 붙여넣는 방식으로 만들었습니다.

```html
<!DOCTYPE html>
<html lang="ko">
<head>
 <meta charset="UTF-8">
 <meta http-equiv="X-UA-Compatible" content="IE=edge">
 <meta name="viewport" content="width=device-width, initial-scale=1.0">
 <link rel="stylesheet" href="main.scss" lang="scss">
 <title>WebRTC Test</title>
</head>
<body>
 <div id="app">
  <div id="videos"></div>
  <textarea id="offer-sdp" cols="30" rows="10"></textarea>
  <textarea id="answer-sdp" cols="30" rows="10"></textarea>
  <button id="offer">create offer</button>
  <button id="answer">create answer</button>
  <button id="save">save answer</button>
 </div>
 <script src="main.js" type="module"></script>
</body>
</html>
```

css는 제외하겠습니다. 보기 편하게 개인 취향에 맞게 조정하시면 되겠습니다. javascript부분은 아래와 같습니다.

```javascript
// src/main.js (frontend)

// 편의상 달러기호($)로 엘리먼트를 잡겠습니다.
const $ = (el) => document.getElementById(el);
let localStream = new MediaStream();
let remoteStream = new MediaStream();
let mypeer = null;

function createVideo() {
  const video = document.createElement("video");
  video.autoplay = true;
  return video;
}

function cover(video) {
  const cover = document.createElement("div");
  cover.classList.add("cover");
  cover.append(video);
  return cover;
}

async function init() {
  const video = createVideo();
  localStream = await navigator.mediaDevices.getUserMedia({
    video: true,
    audio: false,
  });
  video.srcObject = localStream;

  $("videos").insertAdjacentElement("beforeend", cover(video));
}

init();

/* 위 까지 1인 영상이고 아래부터 멀티 작업입니다. */

// google stun server
const PC_CONFIG = {
  iceServers: [
    {
      urls: "stun:stun.l.google.com:19302",
    },
  ],
};

const socket = new WebSocket("ws://localhost:3000");
socket.binaryType = "arraybuffer";
socket.onopen = () => {
  console.log("socket open");
};
socket.onmessage = (message) => {
  console.log("socket message", message);
};
socket.onerror = () => {
  console.log("socket error");
};
socket.onclose = () => {
  console.log("socket close");
};

function createPeer(type) {
  mypeer = new RTCPeerConnection(PC_CONFIG);

  remoteStream = new MediaStream();
  localStream.getTracks().forEach((track) => {
    mypeer.addTrack(track, localStream);
    // 여기서 localStream을 두번째 인자로 넣는 이유는
    // 원격 스트림에 영상을 교환하기 위함입니다.
    // 넣지 않으면 ontrack이벤트가 발생하지 않으니 참고 바랍니다.
  });

  mypeer.ontrack = (e) => {
    console.log(`${type} on track`);
    e.streams[0].getTracks().forEach((track) => {
      remoteStream.addTrack(track);
      // 여기는 track만 추가 합니다.
    });

    const video = createVideo();

    remoteStream = e.streams[0];
    video.srcObject = remoteStream;
    $("videos").insertAdjacentElement("beforeend", cover(video));
  };

  mypeer.onicecandidate = (e) => {
    console.log(`${type} on icecandidate`);
    // candidate가 null이 아니면 socket에 전송 할 것 입니다.
    if (e.candidate) {
      /* 나중에 쓰겠습니다. */
      // socket.send(
      //  JSON.stringify({
      //   type: 'icecandidate',
      //   candidate: e.candidate
      //  })
      // );

      // ice 후보가 교환될때마다 localDescription을 갱신합니다.
      $(`${type}-sdp`).value = JSON.stringify(mypeer.localDescription);
    }
  };
}

async function createOffer() {
  createPeer("offer");

  const offer = await mypeer.createOffer();
  await mypeer.setLocalDescription(offer);

  // 이후 소켓으로 대체될 부분입니다.
  $("offer-sdp").value = JSON.stringify(offer);
}

async function createAnswer() {
  createPeer("answer");

  // 이후 소켓에서 받은 offer가 없으면 작동하지 않도록 하기 위함
  if (!$("offer-sdp").value) return;

  const offer = JSON.parse($("offer-sdp").value);

  mypeer.setRemoteDescription(offer);

  const answer = await mypeer.createAnswer();
  await mypeer.setLocalDescription(answer);

  // 이후 소켓으로 대체될 부분입니다.
  $("answer-sdp").value = JSON.stringify(answer);
}

function saveAnswer() {
  const answer = JSON.parse($("answer-sdp").value);
  mypeer.setRemoteDescription(answer);
}

window.addEventListener("click", (e) => {
  const target = e.target;

  if (target.id === "offer") {
    createOffer();
  }
  if (target.id === "answer") {
    createAnswer();
  }
  if (target.id === "save") {
    saveAnswer();
  }
});
```

## 원리를 살펴보자

완성이 되면 아래처럼 텍스트 적는 폼과 버튼 3개가 있어야합니다. 이제부터 원리를 하나씩 단계별로 확인하면서 어떤 데이터가 어떻게 전송되고 영상이 어느 시점에 어떻게 교환되고 출력되는지 확인하겠습니다.

브라우저 두 개를 켜고 create offer 버튼을 눌러봅니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214224726-15e5472f-1553-426b-8385-0bcd644f66f3.png" alt="sample" title="sample">
   <figcaption>offer 버튼 클릭 후</figcaption>
</span>
</figure>

그러면 이미지처럼 offer부분에 type과 sdp내용이 출력됩니다. 이 offer를 복사해서 그대로 옆 브라우저의 offer란에 붙여넣고 create answer 버튼을 클릭합니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214225175-85bcd0b5-0230-4504-8266-a7a668141988.png" alt="sample" title="sample">
   <figcaption>answer 버튼 클릭 후</figcaption>
</span>
</figure>

얼굴을 가린 검은 박스는 일부러 css로 가린겁니다. 우측 브라우저에 검은 박스가 덩그러니 있는 이유는 ontrack이벤트가 발생해서 비디오태그가 추가되었기 때문입니다. 아직은 영상 데이터가 교환되지 않았으니 상대방 영상이 출력되지 않습니다.

이제 answer가 작성되었으니 요청했던 브라우저에 answer를 붙여넣습니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214225664-dbb09839-977e-4512-9f90-e45bca7c734b.png" alt="sample" title="sample">
   <figcaption>answer를 붙여넣고 save 누르기 전</figcaption>
</span>
</figure>

save 버튼을 이제 누를 차례이기 때문에 강조표시로 css를 조금 변경했습니다. 이제 save answer를 누르게 되면 서로 영상 정보를 교환하고 원격 스트림이 비디오에 출력됩니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214225880-9b7865b5-6544-404e-add5-e945386ec76c.png" alt="sample" title="sample">
   <figcaption>answer를 save한 후</figcaption>
</span>
</figure>

이 과정을 천천히하게 되면 icecandidate 이벤트에 의해 description내용이 달라지기 때문에 타이밍 또한 중요합니다.

이제 지금까지 따라하신 분들은 조금 감이 오셨을 것이라 생각합니다. 선임자나 같이 연구하는 직원이 없기 때문에 필자는 두 가지 방식을 생각하고 있습니다.

1. 들어온 사람이 offer를 보내는 방식
2. 기존에 있는 사람이 들어온 사람을 감지하고 offer를 보내는 방식

즉, offer를 누가 주는지에 대한 순서인데요. 저는 들어오는 인원에 대해서 기존 인원이 offer를 보내는 방식을 취하고 있습니다.

만일 한 명 더 들어와서 3명이 영상교환하려면 어떻게 해야할까요?

## 3인 이상 멀티 스트림 교환을 해보자

원리를 눈치챘다면 이제부터는 소켓으로 어떻게 컨트롤 하는지 문제 밖에 없습니다.

제가 이해한 원리는 아래와 같습니다. A가 B와 데이터를 주고 받으면 추가 인원에 대해서는 추가된 인원들과만 데이터를 교환하면 됩니다. 즉, A-B 관계는 서로 공유 됐기 때문에 더이상 교환하지 않아도 되고, C가 입장하면 A-C, B-C 관계가 서로 공유되야 합니다.
D가 입장하면 A-D, B-D, C-D가 교환되면 4명 모두 서로 영상을 교환하게 됩니다.

예시로 방금 테스트한 브라우저에서 브라우저 하나를 더 열고 테스트해봅시다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214226675-1f9e7858-fc9c-4c49-b285-e3aacc8b42e1.png" alt="sample" title="sample">
   <figcaption>3개의 브라우저</figcaption>
</span>
</figure>

이제 3명이 영상 교환한다고 볼 때 이미 교환된 유저를 A, B라고 가정하고, 새로 켜진 브라우저를 유저 C라고 한다면, A가 B와 교환했던 과정을 A-C, B-C로 교환해주면 됩니다. 먼저, A-C입니다.

똑같이 A에서 create offer 버튼으로 offer를 새로 작성합니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214227000-d09b4337-61b9-4397-9674-6715ebb2147c.png" alt="sample" title="sample">
   <figcaption>A offer to C</figcaption>
</span>
</figure>

C에 붙여넣고 C에서 answer를 작성합니다. 그리고 answer를 A로 다시 주고 save answer 합니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214227153-533eaef1-f236-4ade-be3e-99887aed71e1.png" alt="sample" title="sample">
   <figcaption>C answer to A and save answer</figcaption>
</span>
</figure>

이제 A에 영상이 3개, C에 영상이 2개로 A-C 관계가 성공적으로 영상교환이 되었습니다. B는 여전히 2개 입니다.

이제 B-C관계를 연결해주면 아래와 같이 3인이 영상교환에 성공하게 됩니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214227491-2a738913-5f9f-4cc1-bdf2-f079a7365c0a.png" alt="sample" title="sample">
   <figcaption>3인 영상교환</figcaption>
</span>
</figure>

이 원리를 소켓서버에서 어떻게 전달하고, 현재 textarea에 저장하고 받아오는 방식에 조금의 변형을 주면 접속하자마자 자동으로 영상을 교환하는 화상채팅을 구현할 수 있게 됩니다.

추가적으로 확인차 보여드리자면, 사용자 C가 접속을 끊게 되면 영상 교환도 끊기므로 아래 이미지처럼 나간 사용자의 영상은 멈추게 됩니다. 만일 추후에 나간 사용자의 영상을 지우기 위해 시그널링서버를 통해 나간 유저에 대한 작업을 여러 방법으로 해줄 수도 있습니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214227733-bd672363-47d9-4935-ab20-338201ab34db.png" alt="sample" title="sample">
   <figcaption>사용자 C가 나갔을 때</figcaption>
</span>
</figure>

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/71887242/214228379-430bc784-6eb9-4777-bfad-a6445769bc85.png" alt="sample" title="sample">
   <figcaption>사용자 A를 제외하고 모두 나갔을 때</figcaption>
</span>
</figure>

위의 예시 이미지를 통해 명확히 알수 있는 사실은 교환되었던 각 영상이 B, C의 영상임이 분명해졌습니다.

이번 포스팅은 간단하게 원리를 알아보는 시간을 가지는 것으로 마무리하고, 다음 포스팅에서는 "룸"이라는 개념을 만들어 join하고 서로의 영상을 교환하면서 나간 유저에 대해서 비디오를 삭제하는 간단한 예시를 만들어보겠습니다.

지금까지 포스팅을 읽어주셨으면 따봉이라도 부탁드립니다. 읽어주시는 분들이 있다는 것만으로 포스팅하는데 힘이 됩니다. 😁

---

📚 함께 보면 좋은 내용

[devkimson blog - webrtc 환경구축 포스팅 2편](https://kkn1125.github.io/webrtc02/)

[github - uWebSockets.js](https://github.com/uNetworking/uWebSockets.js/)

[webrtc org](https://webrtc.org/)
