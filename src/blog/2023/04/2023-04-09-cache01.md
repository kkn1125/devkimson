---
slug: "/cache01/"
layout: post
modified: 2023-04-09 14:40:14 +0000
date: 2023-04-09 14:40:14 +0000
title: "[JAVASCRIPT] 캐시 구현과 적용"
author: Kimson
categories: [javascript]
image: https://user-images.githubusercontent.com/113876485/230905977-c8f2a0b4-d946-4216-8671-667bbbfacdcd.png
tags: [cache, FIFO, LFU, LRU, til]
description: "Cache (캐시)

캐시는 느린 기억장치 대신 빠른 기억 장치로 데이터 액세스하여 성능을 향상시키는 기술입니다. 이를테면 CPU, 메모리, 디스크 등 기억 장치 계층 구조에서 빠른 CPU와 느린 기억장치 사이에 중간 계층으로 존재합니다.

예를 들어 네이버를 접속할 때 여러 이미지와 광고, 네이버 로고가 화면에 나옵니다. 매번 접속할 때마다 이 자원들을 불러오는데 1분의 시간이 걸린다고 가정하겠습니다. 그런데 이 자원들을 이미 사용자의 입장에서 가지고 있다면 어떻게 될까요?

즉, 캐시는 이 자원들을 중간 위치에 존재하는 기억장치에 복사 또는 이동해서 가져오는데 걸리는 시간을 줄여 성능을 향상시키고자 하는 기술을 말합니다.

다른 예로는 은행에 대출을 한다고 가정하겠습니다. 대출하기 위해서는 신분증이 필요하지요. 하지만 신분증은 고객이 들고와야 합니다. 이 신분증을 은행에 들릴 때마다 은행이 가지고 있다면 대기 시간이 줄어들고 고객입장에서는 굳이 신분증을 챙겼는지 확인하지 않아도 됩니다.

이 캐시는 API 서버에서도 적용이 됩니다. 이미지, 영상 등의 자원뿐 아니라 API 서버에서도 캐시 정책을 두고 원하는 정책에 따라 사용자에게 응답하는 데이터를 저장해두었다가 요청에 기억해둔 응답을 줄 수 있습니다.

이 포스팅을 작성하는 목적은 우연히 캐시를 구현하고 API서버에 적용한 경험을 기록하고 후기를 공유하기 위함입니다."
featured: true
hidden: false
rating: 4.5
toc: true
profile: false
istop: true
keysum: false
keywords: ""
published: true
---

# Cache (캐시)

캐시는 느린 기억장치 대신 빠른 기억 장치로 데이터 액세스하여 성능을 향상시키는 기술입니다. 이를테면 CPU, 메모리, 디스크 등 기억 장치 계층 구조에서 빠른 CPU와 느린 기억장치 사이에 중간 계층으로 존재합니다.

예를 들어 네이버를 접속할 때 여러 이미지와 광고, 네이버 로고가 화면에 나옵니다. 매번 접속할 때마다 이 자원들을 불러오는데 1분의 시간이 걸린다고 가정하겠습니다. 그런데 이 자원들을 이미 사용자의 입장에서 가지고 있다면 어떻게 될까요?

즉, 캐시는 이 자원들을 중간 위치에 존재하는 기억장치에 복사 또는 이동해서 가져오는데 걸리는 시간을 줄여 성능을 향상시키고자 하는 기술을 말합니다.

다른 예로는 은행에 대출을 한다고 가정하겠습니다. 대출하기 위해서는 신분증이 필요하지요. 하지만 신분증은 고객이 들고와야 합니다. 이 신분증을 은행에 들릴 때마다 은행이 가지고 있다면 대기 시간이 줄어들고 고객입장에서는 굳이 신분증을 챙겼는지 확인하지 않아도 됩니다.

이 캐시는 API 서버에서도 적용이 됩니다. 이미지, 영상 등의 자원뿐 아니라 API 서버에서도 캐시 정책을 두고 원하는 정책에 따라 사용자에게 응답하는 데이터를 저장해두었다가 요청에 기억해둔 응답을 줄 수 있습니다.

이 포스팅을 작성하는 목적은 우연히 캐시를 구현하고 API서버에 적용한 경험을 기록하고 후기를 공유하기 위함입니다.

## 캐시의 동작

캐시의 동작은 단순하게 읽고 쓰기에 대한 방식을 다루는데 있습니다. 요청을 기억하기 위해 쓰기 기능이 사용되고, 사용자에게 저장된 캐시 데이터를 주기 위해 읽기 기능이 사용됩니다. 하지만 캐시는 성능 향상을 위한 기술이지만 잘못 사용하면 데이터 최신화를 방해할 수도 있습니다. 만약, 캐시 데이터가 영구히 보존된다면 어떻게 될까요?

예를 들어 명절을 맞이해서 네이버 로고가 업데이트 되었고, 사용자의 캐시가 영구 보존되도록 설정되었다고 가정하겠습니다. 사용자는 네이버에 접속하게 되면 명절에 맞춰 제작된 로고가 아닌 기존의 로고를 보게 됩니다. 캐시 데이터에 저장된 로고가 영구보존 되어있고, 적용 우선 순위가 캐시 데이터이기 때문입니다.

캐시 데이터는 앞서 말했듯이 성능향상을 위해 중간 기억장치에 저장하여 불러오기 때문에 우선순위가 느린기억 장치에 저장되어 있는 데이터보다 높습니다.

이러한 불상사를 피하고 효율적으로 캐시 데이터를 활용하기 위해 캐시 데이터를 교체하는 정책이 필요하게 됩니다.

## 캐시 교체 정책

캐시 교체 정책으로는 흔히 접할 수 있는 FIFO(First in First out)와 LRU(Least Recently Used, 가장 최근에 사용되지 않은 것), LFU(Least Frequently Used, 가장 적게 사용된 것) 등이 있습니다.

많은 교체 정책이 있지만 이 포스팅에서는 위에 언급한 FIFO, LRU, LFU를 다루고자 합니다. 필자의 주관적인 해석이 섞여 있으니 다른 글과 같이 보시고 판단하시기 바랍니다. 😁

### FIFO

직역하면 선입선출 방식입니다. 먼저 들어온 녀석이 먼저 나가는 방식은 합리적인 방법일 수 있습니다. 하지만 먼저 들어왔다고 해서 먼저 캐시 데이터가 삭제되어 버리면 자주 이용하는 사이트의 캐시 데이터가 먼저 삭제 될 수도 있는 단점이 있습니다. 장점으로는 먼저 생성된 캐시 데이터가 가장 오래된 것이기 때문에 오래된 캐시 데이터를 순차로 삭제할 수 있다는 장점도 있습니다. 마치 편의점에 먼저 들어온 김밥이 시간이 지남에 따라 들어온 순서대로 폐기한다는 것과 유사합니다.

### LRU

캐시 데이터 중 최근 시간 기준으로 사용하지 않아 최근에도 사용하지 않은 캐시 데이터를 교체하는 방식입니다. 이용하는 A, B, C 사이트가 있습니다. A 사이트를 최근에 자주 접속하지 않았습니다. 그러면 LRU정책에 의해 A사이트 캐시 데이터는 교체됩니다. A사이트를 B, C사이트보다 이후에 사용을 했다 하더라도 A 사이트를 최근 기준으로 사용하지 않았다면 교체가 되는 것이지요. 즉, **시간에 대한 기준**으로 **교환 주기를 결정**하게 됩니다.

### LFU

자주 이용되지 않은 것을 교체하는 방식입니다. 이는 빈도의 수를 기준으로 교환 정책이 동작합니다. A, B, C 사이트 중 A 사이트를 제일 마지막에 사용했고, 최근에 사용한 사이트라 하더라도 사용한 빈도 수가 낮다면 A 사이트 캐시 데이터를 교체하는 정책입니다.

## 기능 구현

교체 정책을 알아보았습니다. 위 3가지 정책을 기능 구현해보면서 실제 API에 적용하는 예시를 보면서 포스팅을 마무리하고자 합니다. 위 교체 정책을 모두 적용하지 않을 겁니다. 각 정책마다 장단이 있기 때문에 적용하고자 하는 서비스의 성격과 취지에 맞는 교체 정책을 적용한다면 단순히 요청에 대한 응답을 해주는 API 서버보다 빠른 성능과 효율적인 데이터처리가 되지 않을까 생각합니다.

### 개발 환경

기능 구현에 앞서 간단하게 개발 환경은 다음과 같습니다.

1. *node* - 18.11.0
2. *npm* - 9.6.1
3. *fastify* - 4.15.0
4. *node-schedule* - 2.1.1
5. *pino-pretty* - 10.0.0 (선택사항)

fastify를 사용하고 DB는 사용하지 않고 Map객체로 대체하겠습니다. `pino-pretty`는 로그를 보기 쉽게하기 위함으로 선택사항입니다.

cache를 테스트하기 위해 fastify로 API 서비스를 하나 만들고 필요한 데이터베이스 객체와 레포지토리, 유저 객체를 포함해서 예시를 구현하겠습니다.

구현할 객체는 다음과 같습니다.

- Cache
- CacheManager (Cache를 관리)
- User (Entity)
- Repository
- Database (Repository를 관리)

### API 서비스 구현

> fastify를 사용하여 작성되었습니다.

```javascript
// index.js

import fastify from "fastify";
import CacheManager from "./CacheManager.js";
import Database from "./Repository.js";

/* server settings */
const server = fastify({
  logger: {
    serializers: {
      res(reply) {
        // The default
        return {
          statusCode: reply.statusCode,
        };
      },
      req(request) {
        return {
          method: request.method,
          url: request.url,
          hostname: request.hostname,
          query: request.query,
          body: request.body,
        };
      },
    },
    transport: {
      target: "pino-pretty",
      options: {
        translateTime: "HH:MM:ss Z",
        ignore: "pid,hostname,reqId",
      },
    },
  },
});

/* database */
const db = new Database(["user"]);
const userRepository = db.getDB("user");

/* cache manager */
const cacheManager = new CacheManager();
cacheManager.addPolicy("LFU", function (name) {
  console.log(`[Policy ${name}] check start!`);
  const compare = {
    min: undefined,
    max: undefined,
  };
  Object.entries(this.store).forEach(([db, cache]) => {
    console.log("[Cache]:", cache);
    if (!compare.max) compare.max = cache;
    if (!compare.min) compare.min = cache;

    if (cache.used > compare.max.used) {
      compare.max = cache;
    }
    if (cache.used < compare.min.used) {
      compare.min = cache;
    }
  });
  console.log(compare); // 비교 객체 확인

  if (
    compare.max !== compare.min &&
    compare.max.used - compare.min.used > cacheManager.usedGap
  ) {
    console.log("[Over limit used count]");
    const { method, url } = compare.min.header;
    cacheManager.delete(`${method}|${url}`);
  }
});

server.addHook("onSend", (req, res, payload, done) => {
  const { method, url } = req;
  const header = `${method}|${url}`;
  const isExists = cacheManager.hasCache(header);
  if (req.method === "GET") {
    if (!isExists) {
      cacheManager.save(header, payload);
      console.log("[🚀 Save Cache!]", payload);
    } else {
      cacheManager.updateCacheData(header);
    }
  }
  done();
});

server.get("/api/user", async (req, res) => {
  /* cache injection */
  const cache = cacheManager.read(req);
  if (cache) return cache;

  const users = await userRepository.findAll();
  return { ok: true, payload: users };
});
server.get("/api/user/:id", async (req, res) => {
  const { params } = req;
  try {
    /* cache injection */
    const cache = cacheManager.read(req);
    if (cache) return cache;

    const user = await userRepository.findOne(params.id);
    return { ok: true, payload: user };
  } catch (e) {
    res.status(404).send(
      JSON.stringify({
        ok: false,
        message: "user not found id :" + params.id,
      })
    );
  }
});
server.post("/api/user", async (req, res) => {
  const { params } = req;
  try {
    cacheManager.initialize("user");

    const createdUser = await userRepository.insert(req.body);
    return { ok: true, payload: createdUser };
  } catch (e) {
    res.status(404).send(
      JSON.stringify({
        ok: false,
        message: "user not found id :" + params.id,
      })
    );
  }
});
server.put("/api/user/:id", async (req, res) => {
  const { params } = req;
  try {
    cacheManager.initialize("user");

    const updatedUser = await userRepository.update(params.id, req.body);
    return { ok: true, payload: updatedUser };
  } catch (e) {
    res.status(404).send(
      JSON.stringify({
        ok: false,
        message: "user not found id :" + params.id,
      })
    );
  }
});
server.delete("/api/user/:id", async (req, res) => {
  const { params } = req;
  try {
    cacheManager.initialize("user");
    
    await userRepository.delete(params.id);
    return { ok: true };
  } catch (e) {
    res.status(404).send(
      JSON.stringify({
        ok: false,
        message: "user not found id :" + params.id,
      })
    );
  }
});

server.listen(
  {
    host: "0.0.0.0",
    port: 5000,
  },
  () => {
    console.log("server listening on port 5000");
  }
);
```

이제 위 코드를 하나 씩 뜯어보겠습니다. `38라인`에서 데이터베이스를 생성합니다. `user`만 사용할 것이기 때문에 `user`를 배열에 담아 인자로 넘겨줍니다. 데이터베이스 객체는 이후에 나올테니 초기화하는 용도로 생각하면 됩니다.

그리고 `42라인`부터 캐시매니저의 인스턴스를 생성하고 LFU 정책을 추가합니다. LFU 정책은 필자가 해석한 로직이니 참고만 하시기 바랍니다. 캐시매니저의 인스턴스를 생성하자마자 크론시간으로 5초마다 등록된 정책을 감시합니다. 캐시데이터가 쌓이게 되면 등록된 캐시 중 최대/최소로 사용된 데이터를 서로 비교하고 그 차이가 캐시매니저에 지정해둔 5회 이상 차이가 벌어지게 되면 적게 사용된 캐시데이터를 삭제해서 새로운 데이터를 받도록 하게 합니다.

즉, A캐시가 6번, B캐시가 1번 사용되었다면 B캐시는 삭제됩니다. B캐시는 새로 API가 호출되면 새로운 데이터를 받게 됩니다. 차이를 빠르게 보기위해 크론시간은 5초마다 실행되게 했습니다.

`73라인`의 addHook을 통해 응답하는 시점의 데이터를 캐시에 저장하도록 합니다. 캐시를 저장하는 기준이 되는 키값은 API의 호출 메서드와 경로입니다. 물론 파라미터 포함입니다. form data 또는 raw 데이터를 포함할 수도 있습니다. 현재 작업 중인 프로젝트에는 form body 데이터를 직렬화해서 키값으로 사용하고 있습니다만 보기 쉬운 예제를 위해 포함하지 않았습니다. 해보고 싶은 분은 직접 해보시기 바랍니다.

그리고 캐시를 적용하는 부분은 read 기능을 담당하는 `GET`메서드에 위치 시킵니다. 캐시데이터를 저장하는 것 또한 `GET`메서드만 저장합니다. `POST`나 `PUT` 등의 데이터가 저장되어 버리면 수정, 삭제를 할 때에 제대로 실행 되었는지 알 수 없습니다. 캐시 데이터를 초기화하는 작업 또한 필요합니다. 데이터가 항상 동일하지는 않습니다. 추가, 수정, 삭제되면 캐시 데이터는 쓸모가 없기 때문에 초기화 해주어야 합니다. 때문에 `POST`, `PUT`, `DELETE` 메서드에는 해당 API에 관련된 응답만 제거하기 위해 `initialize`메서드를 위치 시킵니다. `initialize`메서드는 아래에 어떻게 생겼는지 나옵니다.

```javascript
// CacheManager.js

import Cache from "./Cache.js";
import schedule from "node-schedule";

export default class CacheManager {
  /** @type {{[k: string]: Cache}} */ store;
  policy;
  usedGap = 3;
  expiredTime = 1000 * 60 * 60 * 24 * 1;

  constructor(expiredTime) {
    this.store = {};
    this.policy = {};
    this.expiredTime = expiredTime || this.expiredTime;
    this.#startCheckPolicies();
  }

  #startCheckPolicies() {
    /* policy check */
    schedule.scheduleJob(
      "*/5 * * * * *",
      function () {
        console.log("[💻 Policy check]");
        this.validation();
      }.bind(this)
    );
  }

  initialize(key) {
    Object.entries(this.store).forEach(([k, v]) => {
      if (k.match(key)) {
        console.log(`[❌ initialize match store]: cache in ${key} => delete ${k}`);
        delete this.store[k];
      }
    });
  }

  updateCacheData(key) {
    const oldData = this.store[key];
    oldData.updateUsed();
    oldData.updateTime();
    return oldData;
  }

  hasCache(key) {
    return !!this.store[key];
  }

  read(req) {
    const { method, url } = req;
    const header = `${method}|${url}`;
    const item = this.store[header]?.item;
    if (item) {
      console.log("[🚀 Quick Response]", item);
    }
    return item;
  }

  save(key, value) {
    const [method, url] = key.split("|");
    const cacheHeader = { method, url };
    this.store[key] = new Cache(cacheHeader, value, this.expiredTime);
  }

  delete(key) {
    delete this.store[key];
  }

  update(key, newValue) {
    this.store[key] = newValue;
  }

  addPolicy(
    /** @type {string} */ name,
    /** @type {(this: CacheManager, name: string) => void} */ feature
  ) {
    this.policy[name] = feature.bind(
      /** @type {CacheManager} */ this,
      /** @type {string} */ name
    );
  }

  deletePolicy(name) {
    delete this.policy[name];
  }

  validation() {
    if (Object.keys(this.policy).length > 0) {
      Object.entries(this.policy).forEach(([name, policy]) => policy());
    } else {
      console.log("no policy");
    }
  }
}
```

캐시매니저는 복잡한 기능없이 CRUD만 가지고 있습니다. 그저 소비만 하면 되는 구조입니다. 조금 다른 기능이라고 하자면 `startCheckPolicies` 메서드가 되겠습니다. 캐시매니저의 인스턴스를 생성하면 동작하도록 했습니다. 동작하는 시점에 정책이 등록되지 않아도 오류는 발생하지 않습니다. 그 외 `jsdoc`을 사용한 부분은 힌트를 띄우기 위한 것이니 별 의미는 없습니다.

다음으로 Cache 객체입니다.

```javascript
// Cache.js

export default class Cache {
  header;
  item;
  used;
  createdAt;
  updatedAt;
  expiredIn;

  constructor(header, item, expiredIn) {
    this.header = header;
    this.item = JSON.parse(item);
    this.used = 1;
    this.createdAt = Date.now();
    this.updatedAt = Date.now();
    this.expiredIn = Date.now() + expiredIn;
  }

  updateUsed() {
    this.used += 1;
    return this.toJSON();
  }

  updateTime() {
    this.updatedAt = Date.now();
    return this.toJSON();
  }

  toJSON() {
    return Object.assign({}, this);
  }
}
```

캐시 객체는 딱 VO정도의 내용만 담습니다. 초기 생성된 때 사용이되므로 used는 1로 초기화하고 expiredIn은 캐시매니저에서 지정된 유효기간을 받아 생성되는 시간에서 더합니다. 이번 포스팅에서는 LFU만 적용한 예시를 다루기 때문에 만료시간에 따른 정책은 따로 만들어서 테스트해보시기 바랍니다.

used와 updatedAt 멤버 업데이트와 JSON데이터로 가공해서 사용하기 위해 3가지 메서드를 추가했습니다.

다음은 Database와 Repository 객체입니다.

```javascript
// Repository.js

import User from "./User.js";

export class Repository {
  name;
  pk = 0;
  database;

  constructor(repoName, database) {
    this.name = repoName;
    this.database = database || [];
  }

  responseDelay(data) {
    console.log("[📢 Delay Response]");
    return new Promise((resolve) => {
      setTimeout(() => {
        resolve(data);
      }, 500);
    });
  }

  async findAll() {
    return this.responseDelay("findAll", this.database);
  }

  async findOne(id) {
    const found = await this.responseDelay(
      "findOne",
      this.database.find((db) => db.id === Number(id))
    );
    if (!found) throw new Error("not found");
    return found;
  }

  async insert(data) {
    const newData = {
      id: (this.pk += 1),
      ...data,
    };
    let pushData;
    switch (this.name) {
      case "user":
        pushData = new User(newData);
        break;
      default:
        pushData = newData;
        break;
    }
    this.database.push(pushData);
    return this.responseDelay("insert", newData);
  }

  async update(id, data) {
    const foundUser = this.database.find((db) => db.id === Number(id));
    if (!foundUser) throw new Error("not found");
    return this.responseDelay("update", Object.assign(foundUser, data || {}));
  }

  async delete(id) {
    const foundUser = this.database.find((db) => db.id === Number(id));
    if (!foundUser) throw new Error("not found");

    this.database = this.database.filter((db) => db.id !== Number(id));
    return this.responseDelay("delete", true);
  }
}

export default class Database {
  /** @type {Repository[]} */ databases;

  constructor(databaseNames) {
    this.databases = new Map();
    databaseNames.forEach((name) => {
      this.databases.set(name, new Repository(name, []));
    });
  }

  /** @returns {Repository} */
  getDB(name) {
    return this.databases.get(name);
  }
}
```

끊어서 보자면 `5라인`이 저장소입니다. 저장소는 mysql로 치자면 테이블 개념으로 작성했습니다. responseDelay를 사용해서 사용자 요청에 대한 응답 데이터를 의도적으로 500ms 지연시킵니다. 캐시 데이터를 불러올 때와 비교하기 위함입니다. 실제로 500ms까지 걸리는 경우는 드물겠지만, 현재 제가 구축한 API 서버에서는 23ms가 걸리고, 캐시를 적용한 후로는 2ms까지 줄었습니다.

메서드명은 typeorm 또는 스프링의 JPA등을 사용하기 떄문에 일부러 맞추었습니다. 마지막으로 `70라인`에서 데이터베이스 객체는 딱 생성할 때 배열로 테이블 이름을 받습니다. 위에서 봤던 index.js 소스코드에 데이터베이스 인스턴스를 만들 때 인자로 받던 배열이 이것 때문입니다.

생성된 데이터베이스를 불러오는 getDB메서드만 존재합니다. 마지막으로 Repository에 사용될 User객체 입니다.

```javascript
// User.js

export default class User {
  id;
  name;
  age;
  hobby;
  gender;

  constructor({id, name, age, gender, hobby}) {
    this.id = id;
    this.name = name;
    this.age = age;
    this.gender = gender;
    this.hobby = hobby;
  }

  toJSON() {
    return Object.assign({}, this);
  }
}
```

LFU 정책을 추가하고 데이터베이스에서 받아오는 데이터와 캐시 데이터를 가져오는 속도 차이를 보기위해 간단한 예시를 들어보았습니다. 물론 사용하는 데스크탑 또는 노트북에 따라 차이는 있을 수 있지만, 명확하게 나타나는 것은 캐시를 사용했을 때 응답 속도가 눈에 띄게 줄어든다는 것 입니다.

### 기능 테스트

캐시 데이터가 쌓이기 전에는 데이터베이스를 조회해서 응답을 하게 됩니다. 첫 데이터가 출력되는데 걸리는 시간은 당연히 500ms가 넘을 것 입니다. 의도적으로 delayResponse메서드를 거치게 했기 때문이죠.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230785226-c8990fc0-1462-41e0-86e3-023b9e0c701f.png" alt="sample" title="sample">
   <figcaption>크론시간으로 정책 실행</figcaption>
</span>
</figure>

크론시간으로 5초마다 정책을 실행하는 모습입니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230784796-815400dd-602d-4fc8-95f8-38aaaf7b68a5.png" alt="sample" title="sample">
   <figcaption>첫 번째 요청에 대한 응답 딜레이</figcaption>
</span>
</figure>

처음 요청하게 되면 500ms이상의 지연시간이 생깁니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230785570-793d2b40-f91d-440a-9338-748fb6fcad29.png" alt="sample" title="sample">
   <figcaption>첫 요청 후 min, max 비교 (LFU 정책)</figcaption>
</span>
</figure>

첫 번째 요청에 대한 로그 확인입니다. 첫 요청이기 때문에 min, max 캐시 모두 동일합니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230785303-a7a0a05d-8a81-401d-8750-7119fdffb02c.png" alt="sample" title="sample">
   <figcaption>두 번째 요청에 대한 응답 딜레이</figcaption>
</span>
</figure>

다시 요청하게 되면 캐시데이터가 저장되어 있기 때문에 데이터베이스를 조회하지 않고 저장된 캐시 데이터를 바로 응답합니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230785265-b995345f-09e1-407b-a175-a76c0a286b3c.png" alt="sample" title="sample">
   <figcaption>사용자 데이터 추가</figcaption>
</span>
</figure>

이때 사용자 데이터가 추가/수정/삭제 된다면 조회하는 데이터를 업데이트 되야하므로 초기화 작업을 거쳐 사용자 API 캐시 데이터 모두 교체 준비를 합니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230785339-4b8310d1-57e1-4542-b671-d4a1910f9b38.png" alt="sample" title="sample">
   <figcaption>사용자 추가로 인해 캐시 데이터 초기화</figcaption>
</span>
</figure>

사용자가 추가되었기 떄문에 사용자 조회하게 되면 응답 시간이 다시 길어집니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230785389-4b79099c-bed8-4cb2-9ff1-246f85e3bd6c.png" alt="sample" title="sample">
   <figcaption>다시 사용자 조회</figcaption>
</span>
</figure>

이후 다시 요청하면 캐시에 저장된 사용자 데이터를 곧바로 응답하게 됩니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230786078-da8e6732-a4cf-4342-ad78-2ef5cea701ad.png" alt="sample" title="sample">
   <figcaption>전제조회 4, 단일 조회 2</figcaption>
</span>
</figure>

그렇게 요청하다보니 요청한 횟수가 늘었습니다. 이 중에서 가장 적게 요청된 캐시를 삭제해야합니다. 삭제 기준이 되는 횟수 차이는 3회로 설정해두었습니다.

좀 더 요청해서 3회 차이가 발생하도록 하였더니 다음과 같이 캐시를 삭제합니다. 삭제된 로그 부분은 `[Over limit used count]`입니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230786181-017f70bc-d8f6-4c52-b7e7-a4fcf5ab1df0.png" alt="sample" title="sample">
   <figcaption>LFU 정책으로 적은 요청 횟수의 캐시 삭제</figcaption>
</span>
</figure>

이후 정책에 의해 해당 캐시 데이터가 삭제 되었기 때문에 전체 사용자 조회 데이터만 남습니다.

<figure class="text-center">
<span class="w-inline-block">
   <img src="https://user-images.githubusercontent.com/113876485/230786299-fa69283a-4fd8-4d7c-b9e0-923a6d760988.png" alt="sample" title="sample">
   <figcaption>마지막 남은 캐시 데이터</figcaption>
</span>
</figure>

## 마무리

캐시를 알아보고 정책을 구현하고, 적용해서 결과를 눈으로 확인 해 보았는데요. 어쩌면 잘못된 방법으로 이해하거나 구현한 것일지 모릅니다. 모자란 부분은 채워나가도록 하고 피드백은 받아들이고자 합니다.

이것저것 해보고 느끼는 것을 중요시하는 편이라 글로는 이해 못해도 하면서 터득하는 버릇이 있기 때문에 이러한 결과를 공유하면서도 이게 맞나, 혹은 오해하는 사람이 생기면 어쩌지 하는 생각도 듭니다. 필자의 블로그를 보고 영향 받는 사람이 한 손에 꼽을 손가락이 있을까 싶지만 그래도 신경은 쓰이네요 😂

fastify가 캐시를 지원하는 플러그인이 있다고 알고 있습니다. 플러그인을 사용하다보니 필자가 구축하던 환경에서 설정하는 부분이 뜻대로 되지 않는 게 많았습니다. 그래서 시도해보니 의외로 좋은 결과가 나와서 뿌듯했습니다. 또 하나 삽질했다기보다 또 하나 배웠다 셈 치고 캐시를 공부하면서 얻은 내용을 조금이나마 공유하게 되었습니다.

여기까지 보셨다면 감사드립니다! 😁

---

📚 함께 보면 좋은 내용

[위키 - Cache](https://ko.wikipedia.org/wiki/%EC%BA%90%EC%8B%9C)

[위키 - Web Cache](https://ko.wikipedia.org/wiki/%EC%9B%B9_%EC%BA%90%EC%8B%9C)

[NPM - node-schedule](https://www.npmjs.com/package/node-schedule)
